{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJappt3toqj"
   },
   "source": [
    "# Preparation\n",
    "\n",
    "1. `git clone https://github.com/yang-song/score_sde_pytorch.git`\n",
    "\n",
    "2. Install [required packages](https://github.com/yang-song/score_sde_pytorch/blob/main/requirements.txt)\n",
    "\n",
    "3. `cd` into folder `score_sde_pytorch`, launch a local jupyter server and connect to colab following [these instructions](https://research.google.com/colaboratory/local-runtimes.html)\n",
    "\n",
    "4. Download pre-trained [checkpoints](https://drive.google.com/drive/folders/1tFmF_uh57O6lx9ggtZT_5LdonVK2cV-e?usp=sharing) and save them in the `exp` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is DATA\n",
      " Volume Serial Number is 36F3-BD02\n",
      "\n",
      " Directory of d:\\Research\\CDPM\\CIFAR10_Song-SDE\n",
      "\n",
      "2024/05/17  16:30    <DIR>          .\n",
      "2024/05/17  16:38    <DIR>          ..\n",
      "2024/05/17  15:37    <DIR>          __pycache__\n",
      "2024/01/03  19:54    <DIR>          configs\n",
      "2024/01/03  19:54             8,178 controllable_generation.py\n",
      "2024/01/18  20:09         1,000,367 CsubVP_samples.png\n",
      "2024/01/03  19:54             7,236 datasets.py\n",
      "2024/01/03  19:54             1,167 debug.py\n",
      "2024/01/03  19:55             4,952 evaluation.py\n",
      "2024/05/01  22:32    <DIR>          exp\n",
      "2024/01/03  19:55             4,713 likelihood.py\n",
      "2024/01/03  19:55             8,332 losses.py\n",
      "2024/01/03  19:55             2,584 main.py\n",
      "2024/01/03  19:54    <DIR>          models\n",
      "2024/01/03  19:54    <DIR>          op\n",
      "2024/05/14  16:14           997,575 plots.ipynb\n",
      "2024/01/03  19:55               228 requirements.txt\n",
      "2024/01/03  19:55               217 requirements_new.txt\n",
      "2024/01/03  19:55            18,607 run_lib.py\n",
      "2024/01/03  19:57    <DIR>          samples\n",
      "2024/05/14  01:11            17,611 sampling.py\n",
      "2024/05/17  14:42            88,806 Score SDE evaluate.ipynb\n",
      "2024/05/20  13:59             3,374 Score SDE train.ipynb\n",
      "2024/05/17  14:42         1,623,050 Score SDE VE.ipynb\n",
      "2024/05/16  15:58         4,884,010 Score_SDE_CsubVP.ipynb\n",
      "2024/05/17  14:41         4,299,403 Score_SDE_demo_PyTorch.ipynb\n",
      "2024/05/17  15:36             9,464 sde_lib.py\n",
      "2024/01/03  19:55               909 utils.py\n",
      "              20 File(s)     12,980,783 bytes\n",
      "               8 Dir(s)  334,959,398,912 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "!pip install -r ./requirements_new.txt\n",
    "# if GPU\n",
    "!pip install --upgrade \"jax[cpu]\"\n",
    "!pip install --upgrade \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'main.py' --mode train --config configs/csubvp/cifar10_ddpmpp_continuous.py --workdir test --config.training.batch_size=64 --config.eval.enable_sampling=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages\\tensorflow_gan\\python\\estimator\\tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages\\torch\\utils\\cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0520 14:16:28.597183 20736 xla_bridge.py:160] Remote TPU is not linked into jax; skipping remote TPU.\n",
      "I0520 14:16:28.598183 20736 xla_bridge.py:333] Unable to initialize backend 'tpu_driver': Could not initialize backend 'tpu_driver'\n",
      "I0520 14:16:28.611183 20736 xla_bridge.py:333] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: Interpreter Host CUDA\n",
      "I0520 14:16:28.616184 20736 xla_bridge.py:333] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "I0520 14:16:28.622192 20736 dataset_info.py:578] Load dataset info from C:\\Users\\zhaoh\\tensorflow_datasets\\cifar10\\3.0.2\n",
      "W0520 14:16:28.625184 20736 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0520 14:16:28.626185 20736 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0520 14:16:28.627184 20736 dataset_builder.py:528] Reusing dataset cifar10 (C:\\Users\\zhaoh\\tensorflow_datasets\\cifar10\\3.0.2)\n",
      "I0520 14:16:28.657191 20736 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from C:\\Users\\zhaoh\\tensorflow_datasets\\cifar10\\3.0.2\n",
      "W0520 14:16:28.737185 20736 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0520 14:16:28.737185 20736 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0520 14:16:28.738184 20736 dataset_builder.py:528] Reusing dataset cifar10 (C:\\Users\\zhaoh\\tensorflow_datasets\\cifar10\\3.0.2)\n",
      "I0520 14:16:28.753190 20736 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from C:\\Users\\zhaoh\\tensorflow_datasets\\cifar10\\3.0.2\n",
      "I0520 14:16:28.811183 20736 run_lib.py:126] Starting training loop at step 1230001.\n",
      "c:\\Users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "I0520 14:16:41.052221 20736 run_lib.py:136] step: 1230050, training_loss: 1.87349e-02\n",
      "I0520 14:16:48.188058 20736 run_lib.py:136] step: 1230100, training_loss: 3.77040e-02\n",
      "I0520 14:16:48.392020 20736 run_lib.py:149] step: 1230100, eval_loss: 1.15017e-01\n",
      "I0520 14:16:55.562421 20736 run_lib.py:136] step: 1230150, training_loss: 2.00241e-02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Research\\CDPM\\CIFAR10_Song-SDE\\main.py:71\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAGS\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not recognized.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 71\u001b[0m   \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages\\absl\\app.py:300\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, argv, flags_parser)\u001b[0m\n\u001b[0;32m    298\u001b[0m   callback()\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m   \u001b[43m_run_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UsageError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    302\u001b[0m   usage(shorthelp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, detailed_error\u001b[38;5;241m=\u001b[39merror, exitcode\u001b[38;5;241m=\u001b[39merror\u001b[38;5;241m.\u001b[39mexitcode)\n",
      "File \u001b[1;32mc:\\Users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages\\absl\\app.py:251\u001b[0m, in \u001b[0;36m_run_main\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    249\u001b[0m   sys\u001b[38;5;241m.\u001b[39mexit(retval)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m   sys\u001b[38;5;241m.\u001b[39mexit(\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\Research\\CDPM\\CIFAR10_Song-SDE\\main.py:62\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m     60\u001b[0m   logger\u001b[38;5;241m.\u001b[39msetLevel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;66;03m# Run the training pipeline\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m   \u001b[43mrun_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m FLAGS\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;66;03m# Run the evaluation pipeline\u001b[39;00m\n\u001b[0;32m     65\u001b[0m   run_lib\u001b[38;5;241m.\u001b[39mevaluate(FLAGS\u001b[38;5;241m.\u001b[39mconfig, FLAGS\u001b[38;5;241m.\u001b[39mworkdir, FLAGS\u001b[38;5;241m.\u001b[39meval_folder)\n",
      "File \u001b[1;32mD:\\Research\\CDPM\\CIFAR10_Song-SDE\\run_lib.py:135\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config, workdir)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Execute one training step\u001b[39;00m\n\u001b[0;32m    134\u001b[0m loss \u001b[38;5;241m=\u001b[39m train_step_fn(state, batch)\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241m.\u001b[39mlog_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    136\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, training_loss: \u001b[39m\u001b[38;5;132;01m%.5e\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (step, loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[0;32m    137\u001b[0m   writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, step)\n",
      "File \u001b[1;32mc:\\Users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages\\ml_collections\\config_dict\\config_dict.py:806\u001b[0m, in \u001b[0;36mConfigDict.__getattr__\u001b[1;34m(self, attribute)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attribute):\n\u001b[1;32m--> 806\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attribute]\n\u001b[0;32m    808\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run -i \"main.py\" --mode train --config configs/csubvp/cifar10_ncsnpp_continuous_scaled.py --workdir results/csubvp_ncsnpp_continuous_scaled_pretrained --config.training.batch_size=4 --config.eval.enable_sampling=True"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "provenance": [
    {
     "file_id": "17lTrPLTt_0EDXa4hkbHmbAFQEkpRDZnh",
     "timestamp": 1693214118556
    },
    {
     "file_id": "1oSYeFhg25RpDtzWhmdnT4PmPfVyvm4p0",
     "timestamp": 1614761919881
    },
    {
     "file_id": "1dRR_0gNRmfLtPavX2APzUggBuXyjWW55",
     "timestamp": 1613459913693
    },
    {
     "file_id": "1Kt8-REbQTRu_FHyfyjTidQLsqUAYBKZU",
     "timestamp": 1610845013109
    },
    {
     "file_id": "1vrOAauG5mb6sBKK-3mNaXbXNpTjxUCH_",
     "timestamp": 1609717803951
    },
    {
     "file_id": "1fIwDmaZ_TEaUAtLVZx0Z40NLcpoZFjNS",
     "timestamp": 1609182892497
    },
    {
     "file_id": "1UGhmEoIZkG3yFTB6JrO6W_0qIiy-J5Ct",
     "timestamp": 1605928880917
    },
    {
     "file_id": "1M7TynPZHXE-zyoDFkYSgJV-fwMTiUOx4",
     "timestamp": 1601571038007
    },
    {
     "file_id": "1cPRCPU5HeR1EB0Fd8vGTE84UCk22bnRT",
     "timestamp": 1601564963310
    },
    {
     "file_id": "1_pRJ9smZVhuJVUBv6p-fmm5gTIzTf_yM",
     "timestamp": 1601528173425
    },
    {
     "file_id": "1SYEZYsPm9hmgxIv5iaeBB6g0yeyuOlN5",
     "timestamp": 1601070939829
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
