{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJappt3toqj"
   },
   "source": [
    "# Preparation\n",
    "\n",
    "1. `git clone https://github.com/yang-song/score_sde_pytorch.git`\n",
    "\n",
    "2. Install [required packages](https://github.com/yang-song/score_sde_pytorch/blob/main/requirements.txt)\n",
    "\n",
    "3. `cd` into folder `score_sde_pytorch`, launch a local jupyter server and connect to colab following [these instructions](https://research.google.com/colaboratory/local-runtimes.html)\n",
    "\n",
    "4. Download pre-trained [checkpoints](https://drive.google.com/drive/folders/1tFmF_uh57O6lx9ggtZT_5LdonVK2cV-e?usp=sharing) and save them in the `exp` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is DATA\n",
      " Volume Serial Number is 36F3-BD02\n",
      "\n",
      " Directory of d:\\Research\\ContractiveDiffusion\\score_sde_pytorch\n",
      "\n",
      "2023/12/25  16:15    <DIR>          .\n",
      "2023/12/24  17:38    <DIR>          ..\n",
      "2023/12/19  16:02    <DIR>          .git\n",
      "2023/12/19  16:00               254 .gitignore\n",
      "2023/12/19  23:19    <DIR>          .ipynb_checkpoints\n",
      "2023/12/25  16:24    <DIR>          __pycache__\n",
      "2023/12/20  02:09    <DIR>          assets\n",
      "2023/12/24  15:01    <DIR>          configs\n",
      "2023/12/19  16:00             8,178 controllable_generation.py\n",
      "2023/12/19  16:00             7,236 datasets.py\n",
      "2023/12/24  15:29             1,167 debug.py\n",
      "2023/12/19  16:00             4,952 evaluation.py\n",
      "2023/12/22  01:26    <DIR>          exp\n",
      "2023/12/19  16:00            11,357 LICENSE\n",
      "2023/12/19  16:00             4,713 likelihood.py\n",
      "2023/12/19  16:00             8,332 losses.py\n",
      "2023/12/19  16:00             2,141 main.py\n",
      "2023/12/19  16:05    <DIR>          models\n",
      "2023/12/19  16:05    <DIR>          op\n",
      "2023/12/19  16:00            15,339 README.md\n",
      "2023/12/22  02:52               228 requirements.txt\n",
      "2023/12/25  22:52               225 requirements_new.txt\n",
      "2023/12/24  19:52            18,588 run_lib.py\n",
      "2023/12/19  16:00            17,558 sampling.py\n",
      "2023/12/24  17:14         1,601,364 Score SDE VE.ipynb\n",
      "2023/12/22  03:05         3,986,568 Score_SDE_demo_PyTorch.ipynb\n",
      "2023/12/24  15:17             8,890 sde_lib.py\n",
      "2023/12/19  16:00               909 utils.py\n",
      "              18 File(s)      5,697,999 bytes\n",
      "              10 Dir(s)  576,484,524,032 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ml-collections==0.1.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: tensorflow-gan==2.0.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: tensorflow_io in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 3)) (0.23.1)\n",
      "Requirement already satisfied: tensorflow_datasets>=3.1.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: tensorflow==2.8.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 5)) (2.8.1)\n",
      "Requirement already satisfied: tensorflow-addons in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 6)) (0.18.0)\n",
      "Collecting tensorflow-probability==0.16.0 (from -r ./requirements_new.txt (line 7))\n",
      "  Using cached tensorflow_probability-0.16.0-py2.py3-none-any.whl (6.3 MB)\n",
      "Requirement already satisfied: tensorboard>=2.4.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 8)) (2.8.0)\n",
      "Requirement already satisfied: absl-py==0.10.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 9)) (0.10.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 10)) (2.1.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 11)) (0.16.2)\n",
      "Requirement already satisfied: ninja in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from -r ./requirements_new.txt (line 12)) (1.11.1.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from ml-collections==0.1.0->-r ./requirements_new.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from ml-collections==0.1.0->-r ./requirements_new.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: contextlib2 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from ml-collections==0.1.0->-r ./requirements_new.txt (line 1)) (21.6.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.2 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow-gan==2.0.0->-r ./requirements_new.txt (line 2)) (0.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (23.5.26)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (3.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (68.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (0.23.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow==2.8.1->-r ./requirements_new.txt (line 5)) (1.60.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow-probability==0.16.0->-r ./requirements_new.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow-probability==0.16.0->-r ./requirements_new.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow-probability==0.16.0->-r ./requirements_new.txt (line 7)) (0.1.8)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (23.1.0)\n",
      "Requirement already satisfied: dill in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (0.3.7)\n",
      "Requirement already satisfied: future in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (0.18.3)\n",
      "Requirement already satisfied: promise in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (4.66.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow-addons->-r ./requirements_new.txt (line 6)) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow-addons->-r ./requirements_new.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (3.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (0.41.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from torch>=1.7.0->-r ./requirements_new.txt (line 10)) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from torch>=1.7.0->-r ./requirements_new.txt (line 10)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from torch>=1.7.0->-r ./requirements_new.txt (line 10)) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from torch>=1.7.0->-r ./requirements_new.txt (line 10)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from torch>=1.7.0->-r ./requirements_new.txt (line 10)) (2023.12.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from torchvision->-r ./requirements_new.txt (line 11)) (10.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from sympy->torch>=1.7.0->-r ./requirements_new.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tensorflow-metadata->tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (1.62.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from tqdm->tensorflow_datasets>=3.1.0->-r ./requirements_new.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.0->-r ./requirements_new.txt (line 8)) (3.2.2)\n",
      "Installing collected packages: tensorflow-probability\n",
      "  Attempting uninstall: tensorflow-probability\n",
      "    Found existing installation: tensorflow-probability 0.13.0\n",
      "    Uninstalling tensorflow-probability-0.13.0:\n",
      "      Successfully uninstalled tensorflow-probability-0.13.0\n",
      "Successfully installed tensorflow-probability-0.16.0\n",
      "Requirement already satisfied: jax[cpu] in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (0.4.23)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from jax[cpu]) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from jax[cpu]) (1.26.2)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from jax[cpu]) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from jax[cpu]) (1.11.4)\n",
      "Requirement already satisfied: jaxlib==0.4.23 in c:\\users\\zhaoh\\anaconda3\\envs\\diffusion_sde\\lib\\site-packages (from jax[cpu]) (0.4.23)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "!pip install -r ./requirements_new.txt\n",
    "# if GPU\n",
    "!pip install --upgrade \"jax[cpu]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list(flags.FLAGS):\n",
    "      delattr(flags.FLAGS,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-fid==0.3.0\n",
      "pytorch-gan-metrics==0.5.3\n",
      "torch==2.1.2\n",
      "torch-fidelity==0.3.0\n",
      "torchaudio==2.1.2\n",
      "torchmetrics @ file:///home/conda/feedstock_root/build_artifacts/torchmetrics_1701462872995/work\n",
      "torchvision==0.16.2\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | findstr torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0102 07:22:53.818749 139905758868288 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA Interpreter\n",
      "I0102 07:22:53.821113 139905758868288 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "I0102 07:22:53.834276 139905758868288 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0102 07:22:53.840817 139905758868288 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0102 07:22:53.841808 139905758868288 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0102 07:22:53.843045 139905758868288 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0102 07:22:53.901589 139905758868288 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0102 07:22:54.024621 139905758868288 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0102 07:22:54.025779 139905758868288 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0102 07:22:54.027020 139905758868288 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0102 07:22:54.055098 139905758868288 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0102 07:22:55.332686 139905758868288 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0102 07:22:55.336177 139905758868288 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0102 07:22:55.336976 139905758868288 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0102 07:22:55.337851 139905758868288 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0102 07:22:55.363287 139905758868288 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0102 07:22:55.380933 139905758868288 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0102 07:22:55.381445 139905758868288 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0102 07:22:55.382496 139905758868288 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0102 07:22:55.407467 139905758868288 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0102 07:22:55.424600 139905758868288 resolver.py:108] Using /tmp/tfhub_modules to cache modules.\n",
      "I0102 07:22:58.426400 139905758868288 run_lib.py:268] begin checkpoint: 123\n",
      "I0102 07:22:59.866501 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 0\n",
      "/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:914: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  structure[0], [func(*x) for x in entries],\n",
      "/root/miniconda3/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:541: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/root/miniconda3/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py:573: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  _add_elements_to_collection(self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
      "2024-01-02 07:30:30.102567: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-01-02 07:30:30.102920: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-01-02 07:30:30.104816: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-01-02 07:30:30.154390: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-01-02 07:30:30.178263: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.95GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-01-02 07:30:30.179632: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.95GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "I0102 07:30:32.094606 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 1\n",
      "I0102 07:37:59.306622 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 2\n",
      "I0102 07:45:26.862734 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 3\n",
      "I0102 07:52:53.104609 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 4\n",
      "I0102 08:00:18.851122 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 5\n",
      "I0102 08:07:45.782989 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 6\n",
      "I0102 08:15:12.795569 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 7\n",
      "I0102 08:22:40.057656 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 8\n",
      "I0102 08:30:06.706096 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 9\n",
      "I0102 08:37:35.727405 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 10\n",
      "I0102 08:45:06.635672 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 11\n",
      "I0102 08:52:33.785429 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 12\n",
      "I0102 09:00:00.480509 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 13\n",
      "I0102 09:07:26.944122 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 14\n",
      "I0102 09:14:53.047024 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 15\n",
      "I0102 09:22:18.926134 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 16\n",
      "I0102 09:29:46.187086 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 17\n",
      "I0102 09:37:12.055342 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 18\n",
      "I0102 09:44:37.617790 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 19\n",
      "I0102 09:52:04.536711 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 20\n",
      "I0102 09:59:30.050490 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 21\n",
      "I0102 10:06:54.424312 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 22\n",
      "I0102 10:14:19.379889 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 23\n",
      "I0102 10:21:43.924551 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 24\n",
      "I0102 10:29:07.830753 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 25\n",
      "I0102 10:36:31.415493 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 26\n",
      "I0102 10:43:55.415621 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 27\n",
      "I0102 10:51:20.206043 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 28\n",
      "I0102 10:58:44.227021 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 29\n",
      "I0102 11:06:08.008535 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 30\n",
      "I0102 11:13:32.697019 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 31\n",
      "I0102 11:20:56.939682 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 32\n",
      "I0102 11:28:20.664583 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 33\n",
      "I0102 11:35:45.088015 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 34\n",
      "I0102 11:43:08.182060 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 35\n",
      "I0102 11:50:31.718625 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 36\n",
      "I0102 11:57:55.656959 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 37\n",
      "I0102 12:05:19.589884 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 38\n",
      "I0102 12:12:42.666716 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 39\n",
      "I0102 12:20:05.171497 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 40\n",
      "I0102 12:27:28.904480 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 41\n",
      "I0102 12:34:56.853529 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 42\n",
      "I0102 12:42:19.965404 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 43\n",
      "I0102 12:49:43.345009 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 44\n",
      "I0102 12:57:06.849750 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 45\n",
      "I0102 13:04:30.500314 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 46\n",
      "I0102 13:11:53.623896 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 47\n",
      "I0102 13:19:16.735180 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 48\n",
      "I0102 13:26:40.103907 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 49\n",
      "I0102 13:34:03.446009 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 50\n",
      "I0102 13:41:26.990633 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 51\n",
      "I0102 13:48:51.120206 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 52\n",
      "I0102 13:56:14.757768 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 53\n",
      "I0102 14:03:38.472732 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 54\n",
      "I0102 14:11:01.973982 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 55\n",
      "I0102 14:18:25.325669 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 56\n",
      "I0102 14:25:49.038335 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 57\n",
      "I0102 14:33:12.767516 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 58\n",
      "I0102 14:40:36.184505 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 59\n",
      "I0102 14:48:01.250768 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 60\n",
      "I0102 14:55:24.671524 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 61\n",
      "I0102 15:02:48.513705 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 62\n",
      "I0102 15:10:12.053080 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 63\n",
      "I0102 15:17:35.963613 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 64\n",
      "I0102 15:25:00.270356 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 65\n",
      "I0102 15:32:23.666322 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 66\n",
      "I0102 15:39:47.340482 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 67\n",
      "I0102 15:47:10.299385 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 68\n",
      "I0102 15:54:33.677282 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 69\n",
      "I0102 16:01:56.548499 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 70\n",
      "I0102 16:09:19.566858 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 71\n",
      "I0102 16:16:42.566719 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 72\n",
      "I0102 16:24:06.277682 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 73\n",
      "I0102 16:31:30.706083 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 74\n",
      "I0102 16:38:53.539159 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 75\n",
      "I0102 16:46:17.113002 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 76\n",
      "I0102 16:53:44.722375 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 77\n",
      "I0102 17:01:08.611871 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 78\n",
      "I0102 17:08:31.684143 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 79\n",
      "I0102 17:15:57.669798 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 80\n",
      "I0102 17:23:21.744864 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 81\n",
      "I0102 17:30:44.926964 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 82\n",
      "I0102 17:38:09.263855 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 83\n",
      "I0102 17:45:32.469758 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 84\n",
      "I0102 17:52:55.589449 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 85\n",
      "I0102 18:00:18.639849 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 86\n",
      "I0102 18:07:41.764866 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 87\n",
      "I0102 18:15:04.539177 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 88\n",
      "I0102 18:22:27.606266 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 89\n",
      "I0102 18:29:50.981817 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 90\n",
      "I0102 18:37:14.468610 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 91\n",
      "I0102 18:44:38.468217 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 92\n",
      "I0102 18:52:01.806470 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 93\n",
      "I0102 18:59:25.249310 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 94\n",
      "I0102 19:06:49.539449 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 95\n",
      "I0102 19:14:15.070800 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 96\n",
      "I0102 19:21:38.388297 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 97\n",
      "I0102 19:29:01.249679 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 98\n",
      "I0102 19:36:24.521548 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 99\n",
      "I0102 19:43:47.863727 139905758868288 run_lib.py:339] sampling -- ckpt: 123, round: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.8/site-packages/tensorflow_gan/python/eval/classifier_metrics.py:1157: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0102 19:51:25.943727 139905758868288 deprecation.py:610] From /root/miniconda3/lib/python3.8/site-packages/tensorflow_gan/python/eval/classifier_metrics.py:1157: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "I0102 19:51:26.595914 139905758868288 run_lib.py:406] ckpt-123 --- inception_score: 1.004400e+01, FID: 2.743317e+00, KID: 7.270088e-04\n",
      "W0102 19:51:26.598591 139905758868288 run_lib.py:275] Waiting for the arrival of checkpoint_124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/autodl-tmp/zhy-research/score_sde_gcp/main.py:71\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAGS\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not recognized.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 71\u001b[0m   \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/absl/app.py:300\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    298\u001b[0m   callback()\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m   \u001b[43m_run_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UsageError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    302\u001b[0m   usage(shorthelp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, detailed_error\u001b[38;5;241m=\u001b[39merror, exitcode\u001b[38;5;241m=\u001b[39merror\u001b[38;5;241m.\u001b[39mexitcode)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/absl/app.py:251\u001b[0m, in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    249\u001b[0m   sys\u001b[38;5;241m.\u001b[39mexit(retval)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m   sys\u001b[38;5;241m.\u001b[39mexit(\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/autodl-tmp/zhy-research/score_sde_gcp/main.py:65\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     62\u001b[0m   run_lib\u001b[38;5;241m.\u001b[39mtrain(FLAGS\u001b[38;5;241m.\u001b[39mconfig, FLAGS\u001b[38;5;241m.\u001b[39mworkdir)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m FLAGS\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;66;03m# Run the evaluation pipeline\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m   \u001b[43mrun_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFLAGS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAGS\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not recognized.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/autodl-tmp/zhy-research/score_sde_gcp/run_lib.py:277\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(config, workdir, eval_folder)\u001b[0m\n\u001b[1;32m    275\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting for the arrival of checkpoint_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (ckpt,))\n\u001b[1;32m    276\u001b[0m     waiting_message_printed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m   \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Wait for 2 additional mins in case the file exists but is not ready for reading\u001b[39;00m\n\u001b[1;32m    280\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run -i \"main.py\" --mode eval --config configs/csubvp/cifar10_ncsnpp_continuous_scaled.py --workdir results/csubvp_ncsnpp_continuous_scaled_pretrained --config.eval.enable_sampling=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 03:15:29.669543 140350213342016 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: Interpreter CUDA\n",
      "I0103 03:15:29.672681 140350213342016 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "I0103 03:15:29.683490 140350213342016 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0103 03:15:29.690791 140350213342016 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 03:15:29.692051 140350213342016 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 03:15:29.693523 140350213342016 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 03:15:29.769238 140350213342016 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 03:15:29.895970 140350213342016 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 03:15:29.897306 140350213342016 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 03:15:29.899413 140350213342016 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 03:15:29.925691 140350213342016 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0103 03:15:31.229515 140350213342016 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0103 03:15:31.234073 140350213342016 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 03:15:31.235400 140350213342016 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 03:15:31.237006 140350213342016 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 03:15:31.267438 140350213342016 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0103 03:15:31.286269 140350213342016 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 03:15:31.287430 140350213342016 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 03:15:31.288812 140350213342016 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 03:15:31.315193 140350213342016 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0103 03:15:31.333039 140350213342016 resolver.py:108] Using /tmp/tfhub_modules to cache modules.\n",
      "I0103 03:15:33.645518 140350213342016 run_lib.py:268] begin checkpoint: 130\n",
      "I0103 03:15:34.844666 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 0\n",
      "/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:914: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  structure[0], [func(*x) for x in entries],\n",
      "/root/miniconda3/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:541: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/root/miniconda3/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py:573: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  _add_elements_to_collection(self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
      "2024-01-03 03:22:58.112361: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-01-03 03:22:58.149787: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.95GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-01-03 03:22:58.150374: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-01-03 03:22:58.150719: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-01-03 03:22:58.151438: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-01-03 03:22:58.154970: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.95GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "I0103 03:23:00.088553 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 1\n",
      "I0103 03:30:19.931144 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 2\n",
      "I0103 03:37:39.892836 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 3\n",
      "I0103 03:44:59.926341 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 4\n",
      "I0103 03:52:20.243956 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 5\n",
      "I0103 03:59:40.136058 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 6\n",
      "I0103 04:07:00.365330 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 7\n",
      "I0103 04:14:20.501746 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 8\n",
      "I0103 04:21:40.844985 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 9\n",
      "I0103 04:29:00.705077 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 10\n",
      "I0103 04:36:20.268593 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 11\n",
      "I0103 04:43:39.730920 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 12\n",
      "I0103 04:50:59.860442 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 13\n",
      "I0103 04:58:20.345897 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 14\n",
      "I0103 05:05:40.156329 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 15\n",
      "I0103 05:13:00.114953 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 16\n",
      "I0103 05:20:20.357111 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 17\n",
      "I0103 05:27:40.095327 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 18\n",
      "I0103 05:35:00.483669 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 19\n",
      "I0103 05:42:20.259367 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 20\n",
      "I0103 05:49:40.337563 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 21\n",
      "I0103 05:57:00.711697 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 22\n",
      "I0103 06:04:20.777863 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 23\n",
      "I0103 06:11:40.750915 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 24\n",
      "I0103 06:19:01.257230 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 25\n",
      "I0103 06:26:20.919716 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 26\n",
      "I0103 06:33:41.381473 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 27\n",
      "I0103 06:41:01.071699 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 28\n",
      "I0103 06:48:20.560427 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 29\n",
      "I0103 06:55:41.341037 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 30\n",
      "I0103 07:03:01.752209 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 31\n",
      "I0103 07:10:22.102610 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 32\n",
      "I0103 07:17:42.372596 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 33\n",
      "I0103 07:25:02.741866 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 34\n",
      "I0103 07:32:22.646614 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 35\n",
      "I0103 07:39:42.670368 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 36\n",
      "I0103 07:47:02.954776 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 37\n",
      "I0103 07:54:22.799051 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 38\n",
      "I0103 08:01:42.530470 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 39\n",
      "I0103 08:09:02.408294 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 40\n",
      "I0103 08:16:21.674478 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 41\n",
      "I0103 08:23:41.541201 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 42\n",
      "I0103 08:31:01.641004 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 43\n",
      "I0103 08:38:22.393619 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 44\n",
      "I0103 08:45:42.750034 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 45\n",
      "I0103 08:53:02.485669 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 46\n",
      "I0103 09:00:22.187946 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 47\n",
      "I0103 09:07:42.865964 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 48\n",
      "I0103 09:15:02.575229 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 49\n",
      "I0103 09:22:22.884997 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 50\n",
      "I0103 09:29:42.756386 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 51\n",
      "I0103 09:37:03.168255 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 52\n",
      "I0103 09:44:23.420959 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 53\n",
      "I0103 09:51:43.454816 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 54\n",
      "I0103 09:59:03.730824 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 55\n",
      "I0103 10:06:23.421148 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 56\n",
      "I0103 10:13:43.792731 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 57\n",
      "I0103 10:21:04.003843 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 58\n",
      "I0103 10:28:23.444084 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 59\n",
      "I0103 10:35:41.884847 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 60\n",
      "I0103 10:43:00.944992 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 61\n",
      "I0103 10:50:20.342341 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 62\n",
      "I0103 10:57:39.621730 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 63\n",
      "I0103 11:04:58.956932 140350213342016 run_lib.py:339] sampling -- ckpt: 130, round: 64\n"
     ]
    }
   ],
   "source": [
    "%run -i \"main.py\" --mode eval --config configs/csubvp/cifar10_ncsnpp_continuous_scaled.py --workdir results/csubvp_ncsnpp_continuous_scaled_pretrained --config.eval.enable_sampling=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 15:10:58.078897 140373501608768 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA Interpreter\n",
      "I0103 15:10:58.081883 140373501608768 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "I0103 15:10:58.092278 140373501608768 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0103 15:10:58.097786 140373501608768 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 15:10:58.098628 140373501608768 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 15:10:58.099673 140373501608768 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 15:10:58.155613 140373501608768 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 15:10:58.273367 140373501608768 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 15:10:58.274478 140373501608768 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 15:10:58.275709 140373501608768 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 15:10:58.303161 140373501608768 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0103 15:10:59.642761 140373501608768 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0103 15:10:59.645798 140373501608768 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 15:10:59.646498 140373501608768 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 15:10:59.647237 140373501608768 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 15:10:59.673320 140373501608768 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0103 15:10:59.690998 140373501608768 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 15:10:59.691589 140373501608768 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 15:10:59.692434 140373501608768 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 15:10:59.717395 140373501608768 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0103 15:10:59.734976 140373501608768 resolver.py:108] Using /tmp/tfhub_modules to cache modules.\n",
      "I0103 15:11:02.275813 140373501608768 run_lib.py:268] begin checkpoint: 130\n",
      "I0103 15:11:03.692153 140373501608768 run_lib.py:340] sampling -- ckpt: 130, round: 91\n",
      "Exception ignored in: <function _xla_gc_callback at 0x7fa9e888b040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n",
      "    def _xla_gc_callback(*args):\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "%run -i \"main.py\" --mode eval --config configs/csubvp/cifar10_ncsnpp_continuous_scaled.py --workdir results/csubvp_ncsnpp_continuous_scaled_pretrained --config.eval.enable_sampling=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 16:09:41.499217 139944760763200 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: Interpreter CUDA\n",
      "I0103 16:09:41.501834 139944760763200 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "I0103 16:09:41.510981 139944760763200 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0103 16:09:41.516655 139944760763200 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 16:09:41.517368 139944760763200 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 16:09:41.518292 139944760763200 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 16:09:41.574516 139944760763200 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 16:09:41.694892 139944760763200 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 16:09:41.696005 139944760763200 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 16:09:41.697188 139944760763200 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 16:09:41.724043 139944760763200 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0103 16:09:42.882613 139944760763200 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0103 16:09:42.885718 139944760763200 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 16:09:42.886383 139944760763200 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 16:09:42.887144 139944760763200 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 16:09:42.913190 139944760763200 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0103 16:09:42.931382 139944760763200 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0103 16:09:42.932383 139944760763200 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0103 16:09:42.933461 139944760763200 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0103 16:09:42.959909 139944760763200 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0103 16:09:42.977710 139944760763200 resolver.py:108] Using /tmp/tfhub_modules to cache modules.\n",
      "I0103 16:09:45.337364 139944760763200 run_lib.py:268] begin checkpoint: 122\n",
      "I0103 16:09:46.640624 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 0\n",
      "/root/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py:914: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  structure[0], [func(*x) for x in entries],\n",
      "/root/miniconda3/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:541: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/root/miniconda3/lib/python3.8/site-packages/keras/legacy_tf_layers/base.py:573: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  _add_elements_to_collection(self.updates, tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
      "I0103 16:16:18.267349 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 1\n",
      "I0103 16:22:46.495313 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 2\n",
      "I0103 16:29:10.621116 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 3\n",
      "I0103 16:35:34.401937 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 4\n",
      "I0103 16:41:56.809854 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 5\n",
      "I0103 16:48:19.167686 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 6\n",
      "I0103 16:54:43.720923 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 7\n",
      "I0103 17:01:05.997271 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 8\n",
      "I0103 17:07:27.891565 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 9\n",
      "I0103 17:13:49.216655 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 10\n",
      "I0103 17:20:10.705259 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 11\n",
      "I0103 17:26:32.256841 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 12\n",
      "I0103 17:32:55.517192 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 13\n",
      "I0103 17:39:17.511540 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 14\n",
      "I0103 17:45:39.738517 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 15\n",
      "I0103 17:52:02.684768 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 16\n",
      "I0103 17:58:25.055091 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 17\n",
      "I0103 18:04:47.344088 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 18\n",
      "I0103 18:11:10.128496 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 19\n",
      "I0103 18:17:32.092355 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 20\n",
      "I0103 18:23:54.480223 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 21\n",
      "I0103 18:30:17.115353 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 22\n",
      "I0103 18:36:38.825553 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 23\n",
      "I0103 18:43:00.468842 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 24\n",
      "I0103 18:49:22.403374 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 25\n",
      "I0103 18:55:45.199318 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 26\n",
      "I0103 19:02:07.482297 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 27\n",
      "I0103 19:08:29.751809 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 28\n",
      "I0103 19:14:52.213036 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 29\n",
      "I0103 19:21:14.684990 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 30\n",
      "I0103 19:27:37.844946 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 31\n",
      "I0103 19:34:00.527893 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 32\n",
      "I0103 19:40:22.774433 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 33\n",
      "I0103 19:46:45.256382 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 34\n",
      "I0103 19:53:07.262669 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 35\n",
      "I0103 19:59:28.867586 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 36\n",
      "I0103 20:05:51.038108 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 37\n",
      "I0103 20:12:13.626520 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 38\n",
      "I0103 20:18:36.301502 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 39\n",
      "I0103 20:24:58.462075 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 40\n",
      "I0103 20:31:21.737060 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 41\n",
      "I0103 20:37:44.293325 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 42\n",
      "I0103 20:44:05.862894 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 43\n",
      "I0103 20:50:28.004230 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 44\n",
      "I0103 20:56:50.557323 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 45\n",
      "I0103 21:03:12.760995 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 46\n",
      "I0103 21:09:35.594768 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 47\n",
      "I0103 21:15:57.923728 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 48\n",
      "I0103 21:22:20.129651 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 49\n",
      "I0103 21:28:42.860545 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 50\n",
      "I0103 21:35:04.798194 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 51\n",
      "I0103 21:41:27.513204 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 52\n",
      "I0103 21:47:50.215046 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 53\n",
      "I0103 21:54:12.504207 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 54\n",
      "I0103 22:00:34.345939 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 55\n",
      "I0103 22:06:55.772615 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 56\n",
      "I0103 22:13:17.378923 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 57\n",
      "I0103 22:19:38.673551 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 58\n",
      "I0103 22:26:01.823451 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 59\n",
      "I0103 22:32:24.584248 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 60\n",
      "I0103 22:38:46.783062 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 61\n",
      "I0103 22:45:09.175675 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 62\n",
      "I0103 22:51:31.966138 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 63\n",
      "I0103 22:57:54.730157 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 64\n",
      "I0103 23:04:17.220422 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 65\n",
      "I0103 23:10:39.314660 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 66\n",
      "I0103 23:17:01.690757 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 67\n",
      "I0103 23:23:25.995780 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 68\n",
      "I0103 23:29:48.536188 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 69\n",
      "I0103 23:36:11.141550 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 70\n",
      "I0103 23:42:32.958534 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 71\n",
      "I0103 23:48:55.545438 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 72\n",
      "I0103 23:55:17.550928 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 73\n",
      "I0104 00:01:38.664367 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 74\n",
      "I0104 00:08:00.857616 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 75\n",
      "I0104 00:14:23.026256 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 76\n",
      "I0104 00:20:45.266226 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 77\n",
      "I0104 00:27:07.695119 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 78\n",
      "I0104 00:33:29.732861 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 79\n",
      "I0104 00:39:51.447922 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 80\n",
      "I0104 00:46:14.246902 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 81\n",
      "I0104 00:52:36.906701 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 82\n",
      "I0104 00:58:58.183949 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 83\n",
      "I0104 01:05:20.374821 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 84\n",
      "I0104 01:11:42.391673 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 85\n",
      "I0104 01:18:04.513385 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 86\n",
      "I0104 01:24:27.023072 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 87\n",
      "I0104 01:30:49.526771 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 88\n",
      "I0104 01:37:11.120423 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 89\n",
      "I0104 01:43:33.575934 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 90\n",
      "I0104 01:49:54.999672 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 91\n",
      "I0104 01:56:17.323537 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 92\n",
      "I0104 02:02:38.682156 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 93\n",
      "I0104 02:09:00.530929 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 94\n",
      "I0104 02:15:22.633495 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 95\n",
      "I0104 02:21:45.231620 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 96\n",
      "I0104 02:28:08.136251 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 97\n",
      "I0104 02:34:29.933480 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 98\n",
      "I0104 02:40:52.367718 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 99\n",
      "I0104 02:47:14.559939 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 100\n",
      "I0104 02:53:36.935226 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 101\n",
      "I0104 02:59:59.087383 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 102\n",
      "I0104 03:06:20.968336 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 103\n",
      "I0104 03:12:43.136354 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 104\n",
      "I0104 03:19:05.251367 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 105\n",
      "I0104 03:25:26.980488 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 106\n",
      "I0104 03:31:49.596897 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 107\n",
      "I0104 03:38:11.372347 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 108\n",
      "I0104 03:44:33.308363 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 109\n",
      "I0104 03:50:55.212179 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 110\n",
      "I0104 03:57:17.071100 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 111\n",
      "I0104 04:03:38.739974 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 112\n",
      "I0104 04:10:00.637092 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 113\n",
      "I0104 04:16:23.022546 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 114\n",
      "I0104 04:22:45.249614 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 115\n",
      "I0104 04:29:08.310709 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 116\n",
      "I0104 04:35:31.238402 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 117\n",
      "I0104 04:41:54.085355 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 118\n",
      "I0104 04:48:16.362855 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 119\n",
      "I0104 04:54:39.003080 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 120\n",
      "I0104 05:01:01.373255 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 121\n",
      "I0104 05:07:23.595946 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 122\n",
      "I0104 05:13:46.572946 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 123\n",
      "I0104 05:20:09.441561 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 124\n",
      "I0104 05:26:31.852211 139944760763200 run_lib.py:340] sampling -- ckpt: 122, round: 125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.8/site-packages/tensorflow_gan/python/eval/classifier_metrics.py:1157: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0104 05:33:07.830235 139944760763200 deprecation.py:610] From /root/miniconda3/lib/python3.8/site-packages/tensorflow_gan/python/eval/classifier_metrics.py:1157: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "I0104 05:33:08.164769 139944760763200 run_lib.py:407] ckpt-122 --- inception_score: 9.932623e+00, FID: 2.704842e+00, KID: 7.026560e-04\n"
     ]
    }
   ],
   "source": [
    "%run -i \"main.py\" --mode eval --config configs/csubvp/cifar10_ncsnpp_continuous_scaled.py --workdir results/csubvp_ncsnpp_continuous_scaled_pretrained --config.eval.enable_sampling=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/miniconda3/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0104 07:45:06.838078 140594394874688 xla_bridge.py:603] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA Interpreter\n",
      "I0104 07:45:06.840259 140594394874688 xla_bridge.py:603] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "I0104 07:45:06.848395 140594394874688 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0104 07:45:06.854609 140594394874688 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0104 07:45:06.855576 140594394874688 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0104 07:45:06.856690 140594394874688 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0104 07:45:06.912530 140594394874688 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0104 07:45:07.030503 140594394874688 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0104 07:45:07.031639 140594394874688 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0104 07:45:07.032952 140594394874688 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0104 07:45:07.060392 140594394874688 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0104 07:45:08.309585 140594394874688 dataset_info.py:578] Load dataset info from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0104 07:45:08.313203 140594394874688 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0104 07:45:08.313951 140594394874688 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0104 07:45:08.314802 140594394874688 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0104 07:45:08.341815 140594394874688 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split train, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "W0104 07:45:08.359877 140594394874688 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "W0104 07:45:08.360576 140594394874688 options.py:556] options.experimental_threading is deprecated. Use options.threading instead.\n",
      "I0104 07:45:08.361671 140594394874688 dataset_builder.py:528] Reusing dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
      "I0104 07:45:08.387952 140594394874688 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split test, from /root/tensorflow_datasets/cifar10/3.0.2\n",
      "I0104 07:45:08.405448 140594394874688 resolver.py:108] Using /tmp/tfhub_modules to cache modules.\n",
      "I0104 07:45:11.079353 140594394874688 run_lib.py:268] begin checkpoint: 121\n",
      "I0104 07:45:12.427889 140594394874688 run_lib.py:340] sampling -- ckpt: 121, round: 0\n"
     ]
    }
   ],
   "source": [
    "%run -i \"main.py\" --mode eval --config configs/csubvp/cifar10_ncsnpp_continuous_scaled.py --workdir results/csubvp_ncsnpp_continuous_scaled_pretrained --config.eval.enable_sampling=True"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "provenance": [
    {
     "file_id": "17lTrPLTt_0EDXa4hkbHmbAFQEkpRDZnh",
     "timestamp": 1693214118556
    },
    {
     "file_id": "1oSYeFhg25RpDtzWhmdnT4PmPfVyvm4p0",
     "timestamp": 1614761919881
    },
    {
     "file_id": "1dRR_0gNRmfLtPavX2APzUggBuXyjWW55",
     "timestamp": 1613459913693
    },
    {
     "file_id": "1Kt8-REbQTRu_FHyfyjTidQLsqUAYBKZU",
     "timestamp": 1610845013109
    },
    {
     "file_id": "1vrOAauG5mb6sBKK-3mNaXbXNpTjxUCH_",
     "timestamp": 1609717803951
    },
    {
     "file_id": "1fIwDmaZ_TEaUAtLVZx0Z40NLcpoZFjNS",
     "timestamp": 1609182892497
    },
    {
     "file_id": "1UGhmEoIZkG3yFTB6JrO6W_0qIiy-J5Ct",
     "timestamp": 1605928880917
    },
    {
     "file_id": "1M7TynPZHXE-zyoDFkYSgJV-fwMTiUOx4",
     "timestamp": 1601571038007
    },
    {
     "file_id": "1cPRCPU5HeR1EB0Fd8vGTE84UCk22bnRT",
     "timestamp": 1601564963310
    },
    {
     "file_id": "1_pRJ9smZVhuJVUBv6p-fmm5gTIzTf_yM",
     "timestamp": 1601528173425
    },
    {
     "file_id": "1SYEZYsPm9hmgxIv5iaeBB6g0yeyuOlN5",
     "timestamp": 1601070939829
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
